import numpy as np
import pandas as pd

from lib.test_specs import TestSpecs

def expand_dict_like_columns(df: pd.DataFrame, regex_for_dict_like: str) -> pd.DataFrame:
    """
    Expands dict-like (or JSON-like) columns in a DataFrame into separate columns.

    Args:
        df (pd.DataFrame): The input DataFrame containing dict-like columns to expand.
        regex_for_dict_like (str): A regex pattern to identify columns 
                                   that contain dict-like structures.

    Returns:
        pd.DataFrame: A new DataFrame where designated dict-like columns 
                      are expanded into individual columns, with their keys as new columns.
                      The names of the expanded columns are prefixed with the original column name.
    """
    # Identify dict-like columns in the DataFrame based on the provided regex pattern.
    dict_like_columns = df.filter(regex=regex_for_dict_like)
    
    # Extract all non-dict-like columns by excluding dict-like ones.
    df_except_dictlike = df.loc[:, ~(df.columns.isin(dict_like_columns.columns))]

    # Initialize the final DataFrame starting with non-dict-like columns.
    final_df = df_except_dictlike

    # Iterate over the identified dict-like columns to expand their contents.
    for col_dict_name, col_dict in dict_like_columns.items():
        # Expand each dict-like column using `pd.json_normalize` and add a prefix for clarity.
        expanded_column = pd.json_normalize(col_dict, meta_prefix=True).add_prefix(f"{col_dict_name}.")  # type: ignore

        # Concatenate the expanded columns into the final DataFrame.
        final_df = pd.concat([final_df, expanded_column], axis=1)

    # Return the new DataFrame with expanded columns.
    return final_df


def create_normative_table(test_specs: TestSpecs, norms_data: pd.DataFrame, type: str) -> pd.DataFrame:
    """
    Creates a normative table for psychological scales based on test specifications
    and normative data. The resulting table includes raw scores and corresponding
    normalized T-scores for each scale.

    Args:
        test_specs (TestSpecs): An object providing configuration for test 
                                specifications such as maximum Likert scale values
                                and scale definitions (names and items for each scale).
        norms_data (pd.DataFrame): A DataFrame containing the normative data for the scales. 
                                   This must include scale names, mean scores, standard
                                   deviations ('ds'), and a unique norms ID for each entry.
        type (str): Specifies the type of normative table (raw, raw_corrected or mean).

    Returns:
        pd.DataFrame: A DataFrame containing the normative T-scores table with the following columns:
                      - 'norms_id': ID of the normative data entry.
                      - 'scale': Name of the psychological scale.
                      - 'raw': The raw scores.
                      - 'std': The standardized T-scores (scaled between 0 and 150).
    """
    # Initialize an empty DataFrame to store the normative table.
    norms_table = pd.DataFrame()

    # Get the maximum Likert-scale value from test specifications.
    likert_max = test_specs.get_spec("likert.max")

    # Iterate over norms_id
    for norms_id in norms_data["norms_id"].unique():

        # Iterate over each scale defined in the test specifications.
        for scale_name, items_straight, items_reversed in test_specs.get_spec("scales"):

            # Filter the norms data for the current scale and norms_id.
            condition = np.logical_and(
                 norms_data["norms_id"].eq(norms_id),
                 norms_data["scale"].eq(scale_name)
            )
        
            # Filter the norms data for the current scale.
            scale_norms_data = norms_data[condition]

            # Extract the mean and standard deviation ('ds') for the current scale.
            scale_mean = scale_norms_data["mean"].iloc[0]
            scale_ds = scale_norms_data["ds"].iloc[0]
            
            # Calculate the total number of items in the scale.
            scale_length = len([*items_straight, *items_reversed])
            
            # Generate the range of raw scores depending on the specified type.
            if type == "mean":
                # Raw scores are generated with steps of 0.05 if type is 'mean'.
                scale_raw_scores = pd.Series(np.arange(0, likert_max + 0.05, 0.05)).round(2)
            else:
                # Raw scores are integers up to the maximum possible score.
                scale_raw_scores = pd.Series(range(0, scale_length * likert_max + 1))
            
            # Compute the normative table entries for the current scale.
            scale_norms = pd.DataFrame({
                "norms_id": norms_id,   # Norms ID.
                "scale": scale_name,                                # Scale name.
                "raw": scale_raw_scores,                            # Raw scores.
                "std": scale_raw_scores                             
                    .sub(scale_mean)                               # Subtract the mean.
                    .div(scale_ds)                                 # Divide by the standard deviation.
                    .mul(10)                                       # Multiply by 10 to calculate T-scores.
                    .add(50)                                       # Add 50 to adjust to T-score range.
                    .clip(0, 200)                                  # Clip values between 0 and 150.
                    .astype(int),                                  # Convert T-scores to integers.
                "std_interpretation": "â—¦"                          # Placeholder for interpretation.
            })
            
            # Append the current scale's normative data to the overall table.
            norms_table = pd.concat([norms_table, scale_norms])

    # Reset the index of the final norms table and return it.
    return norms_table.reset_index(drop=True)
